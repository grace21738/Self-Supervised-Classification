{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed8c424",
   "metadata": {},
   "source": [
    "# Lab1 - Self-Supervised Learning (SSL)\n",
    "\n",
    "In this course, we will focus on the main steps of implementing [SimCLR](https://proceedings.mlr.press/v119/chen20j) in PyTorch.\n",
    "\n",
    "1. Image Preprocessing and Augmentation\n",
    "2. NT-Xent Loss\n",
    "3. Leave-one-out KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa04058",
   "metadata": {},
   "source": [
    "## 1. Image Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66938e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from torchsummary import summary\n",
    "import torch.utils.data as data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c57b3909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n",
      "11.6\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f639bd3",
   "metadata": {},
   "source": [
    "## Get Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "464cb36e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系統找不到指定的路徑。: '.\\\\data\\\\unlabeled'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27484\\1579293649.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtrain_dir_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mall_file_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dir_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_file_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mroot_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系統找不到指定的路徑。: '.\\\\data\\\\unlabeled'"
     ]
    }
   ],
   "source": [
    "root_train = '.\\\\data\\\\unlabeled\\\\'\n",
    "root_test = '.\\\\data\\\\test\\\\'\n",
    "BATCH_SIZE = 256\n",
    "TEMPERATURE = 0.07\n",
    "EPOCH = 500\n",
    "CHANNEL = 3\n",
    "\n",
    "# Load Training Data\n",
    "train_data = []\n",
    "train_dir_path = os.path.dirname(root_train)\n",
    "all_file_name = os.listdir(train_dir_path)\n",
    "for name in all_file_name:\n",
    "    train_data.append( Image.open(os.path.join( root_train,name)) )\n",
    "\n",
    "#Load Test Data\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_dir_path = os.path.dirname(root_test)\n",
    "test_img_data = datasets.ImageFolder( test_dir_path, transform = transform_test )\n",
    "test_loader = data.DataLoader( test_img_data, batch_size=BATCH_SIZE, shuffle=True )\n",
    "print( test_img_data[0][0].shape )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd81aae",
   "metadata": {},
   "source": [
    "## Testing augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfbe34ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jimmy is handsome monkey\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(60),\n",
    "    transforms.RandomResizedCrop(size=96, scale=(0.2, 0.6)),\n",
    "    transforms.GaussianBlur(kernel_size=9,sigma=(0.1, 0.8)),\n",
    "])\n",
    "#display( trans(train_data[0]) )\n",
    "print(\"Jimmy is handsome monkey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002abf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES = len( all_file_name )\n",
    "TEST_NUM_IMAGE =  len( test_img_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d867e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. The (N)ormalized (T)emperature-scaled (C)ross (Ent)ropy Loss (NT-Xent)\n",
    "\n",
    "### Notation Definition\n",
    "\n",
    "- Let $u$ and $v$ be the encoded features of an image in different views (different augmentation).\n",
    "\n",
    "- The similarity of $u$ and $v$ is defined as $\\text{sim}(u,v)=\\frac{u^Tv}{\\vert u\\vert\\vert v\\vert}$.\n",
    "\n",
    "- For a batch of $N$ images, there are $2N$ encoded features:\n",
    "\n",
    "    $$\n",
    "    \\{z_i\\}_{i=1}^{2N}=\\{u_1,u_2,\\cdots,u_N,v_1,v_2,\\cdots,v_N\\}\n",
    "    $$\n",
    "\n",
    "### Designs a loss function to learn that the feature $u_i$ can figure out $v_i$ from $(2N-1)$ features.\n",
    "\n",
    "Let $z_i$ be the reference feature. We can use cross entropy loss (negative log softmax) to make $z_i$ and $z_j$ closer and make $z_i$ father away from $z_k,\\forall k\\neq j$ at the same time.\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{i,j}=-\\log\\Bigg(\\frac{\\exp\\big(\\frac{\\text{sim}(z_i,z_j)}{\\tau}\\big)}{\\sum_{k=1}^{2N}\\mathbb 1[k\\neq i]\\exp\\big(\\frac{\\text{sim}(z_i,z_k)}{\\tau}\\big)}\\Bigg)\n",
    "$$\n",
    "\n",
    "where $\\tau \\le 1$ is a constant to scale up the output range of $\\text{sim}(\\cdot,\\cdot)$ from $[-1, 1]$ to $[\\frac{-1}{\\tau},\\frac{1}{\\tau}]$.\n",
    "\n",
    "Consider all ordered pairs $(u_i, v_i)$ and $(v_i, u_i)$, $\\forall i \\in \\{1,\\cdots,N\\}$\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{NT-Xent}}=\\frac{1}{2N}\\sum_{i=1}^N \\mathcal{L}_{i,i+N} + \\mathcal{L}_{i+N,i}\n",
    "$$\n",
    "\n",
    "### Implementation\n",
    "In following, we provide an implementation of batchify NT-Xent loss which does not contain any **for loop** at python level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xt_xent(\n",
    "    u: torch.Tensor,                               # [N, C]\n",
    "    v: torch.Tensor,                               # [N, C]\n",
    "    temperature: float = TEMPERATURE,\n",
    "):\n",
    "    \"\"\"\n",
    "    N: batch size\n",
    "    C: feature dimension\n",
    "    \"\"\"\n",
    "    N, C = u.shape\n",
    "    #print( 'N, C:',N,C )\n",
    "    # torch.cat是将两个张量（tensor）拼接在一起，cat是concatnate的意思 -> dim = 0接在下面\n",
    "    z = torch.cat([u, v], dim=0)                   # [2N, C]\n",
    "    z = F.normalize(z, p=2, dim=1)                 # [2N, C]\n",
    "    s = torch.matmul(z, z.t()) / temperature       # [2N, 2N] similarity matrix\n",
    "    mask = torch.eye(2 * N).bool().to(z.device)    # [2N, 2N] identity matrix\n",
    "    s = torch.masked_fill(s, mask, -float('inf'))  # fill the diagonal with negative infinity -> k!=i 的部分\n",
    "    label = torch.cat([                            # [2N]\n",
    "        torch.arange(N, 2 * N),                    # {N, ..., 2N - 1}\n",
    "        torch.arange(N),                           # {0, ..., N - 1}\n",
    "    ]).to(z.device)\n",
    "    #print('label:', label)\n",
    "    #print('s:i', s)\n",
    "    loss = F.cross_entropy(s, label)               # NT-Xent loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cf54cb",
   "metadata": {},
   "source": [
    "### Transform order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1853be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms.RandomOrder\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(90),\n",
    "    transforms.RandomResizedCrop(size=96, scale=(0.2, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981e90c",
   "metadata": {},
   "source": [
    "# SimCLR CNN\n",
    "Define a single layer CNN as the image encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, projhead = 256, emd_dim = 512):\n",
    "        super().__init__()\n",
    "        resnet18 = torchvision.models.resnet18(weights=None)\n",
    "        resnet18.fc = Identity()\n",
    "        self.encoder = resnet18\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(emd_dim, projhead),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(projhead, projhead)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        encoding = self.encoder(x)\n",
    "        projection = self.projection(encoding)  \n",
    "        return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250fe13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class LinearEvaluation(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        simclr = deepcopy(model)\n",
    "        simclr.projection = Identity()\n",
    "        self.simclr = simclr\n",
    "        for param in self.simclr.parameters():\n",
    "            param.requires_grad = False\n",
    "    def forward(self, x):\n",
    "        encoding = self.simclr(x)\n",
    "        #pred = self.linear(encoding) \n",
    "        return encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a355c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (projection): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "simclr_model = SimCLR()\n",
    "simclr_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254af10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Leave-one-out Cross Validation with K-Nearest Neighbors (KNN)\n",
    "- Leave-one-out Cross Validation\n",
    "    \n",
    "    For each data, the other data are training data.\n",
    "\n",
    "- KNN\n",
    "    \n",
    "    An object is classified by a plurality vote of its $K$ neighbors in training data.\n",
    "\n",
    "### Implementation\n",
    "For KNN, the space complexity is $O(N^2\\times C)$ where $N$ is the number of data and $C$ is the dimension of feature size. We provide a batchify implementation to reduce memory footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(emb, cls, batch_size, Ks=[1, 10, 50, 100]):\n",
    "    \"\"\"Apply KNN for different K and return the maximum acc\"\"\"\n",
    "    preds = []\n",
    "    mask = torch.eye(batch_size).bool().to(emb.device)\n",
    "    mask = F.pad(mask, (0, len(emb) - batch_size))\n",
    "    for batch_x in torch.split(emb, batch_size):\n",
    "        dist = torch.norm(\n",
    "            batch_x.unsqueeze(1) - emb.unsqueeze(0), dim=2, p=\"fro\")\n",
    "        now_batch_size = len(batch_x)\n",
    "        mask = mask[:now_batch_size]\n",
    "        dist = torch.masked_fill(dist, mask, float('inf'))\n",
    "        # update mask\n",
    "        mask = F.pad(mask[:, :-now_batch_size], (now_batch_size, 0))\n",
    "        pred = []\n",
    "        for K in Ks:\n",
    "            knn = dist.topk(K, dim=1, largest=False).indices\n",
    "            knn = cls[knn].cpu()\n",
    "            pred.append(torch.mode(knn).values)\n",
    "        pred = torch.stack(pred, dim=0)\n",
    "        preds.append(pred)\n",
    "    preds = torch.cat(preds, dim=1)\n",
    "    accs = [(pred == cls.cpu()).float().mean().item() for pred in preds]\n",
    "    return max(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb87fb35",
   "metadata": {},
   "source": [
    "## [ First ] Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b450285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract feature\n",
    "max_acc = 0.97\n",
    "lr = 0.001 \n",
    "optimizer = torch.optim.Adam(simclr_model.parameters(), lr=lr)\n",
    "simclr_model.to(device)\n",
    "loss_list = []\n",
    "for epoch in range(1, EPOCH + 1):\n",
    "    total_loss = 0\n",
    "    x1 = torch.stack([transform(train_data[idx]) for idx in range(NUM_IMAGES)])\n",
    "    x2 = torch.stack([transform(train_data[idx]) for idx in range(NUM_IMAGES)])\n",
    "    train_loader_1 = data.DataLoader(x1, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    train_loader_2 = data.DataLoader(x2, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    for batch_idx, (data_1,data_2) in enumerate(zip(train_loader_1,train_loader_2)):\n",
    "        data_1,data_2 = data_1.to(device), data_2.to(device)\n",
    "        #print( data_1.shape )\n",
    "        optimizer.zero_grad()\n",
    "        u = simclr_model(data_1)\n",
    "        v = simclr_model(data_2)\n",
    "        loss = xt_xent(u, v)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 查看 loss 情況 ###\n",
    "        total_loss +=loss.item()\n",
    "    print(f'Epoch {epoch}: ' +\n",
    "            f'  Loss: {total_loss/29:.6f}')\n",
    "    #### Validation 狀況 ###\n",
    "    val_model = deepcopy(simclr_model)\n",
    "    eval_model = LinearEvaluation(val_model).to(device)\n",
    "    eval_model.to(device)\n",
    "    for batch_idx, (val_data, label) in enumerate(test_loader):\n",
    "        val_data,label = val_data.to(device), label.to(device)\n",
    "        emd_data = eval_model(val_data)\n",
    "        if batch_idx == 0:\n",
    "            embed = emd_data\n",
    "            labels = label\n",
    "        else:\n",
    "            embed = torch.cat((embed,emd_data),0)\n",
    "            labels = torch.cat((labels,label),0)\n",
    "            #print('EBD SHAPE',embed.shape)\n",
    "            #print('Label',labels.shape)\n",
    "    acc = KNN(embed, labels, batch_size=BATCH_SIZE)\n",
    "    print(\"Val Accuracy: %.5f\" % acc)\n",
    "    if acc >= max_acc:\n",
    "        max_acc = acc\n",
    "        torch.save(simclr_model,'./best.pth')\n",
    "        \n",
    "    ### 儲存 checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5492a",
   "metadata": {},
   "source": [
    "## [ Second ] Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2362fc03",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4060\\39630824.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_IMAGES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_IMAGES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtrain_loader_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Extract feature\n",
    "max_acc = 0.974\n",
    "simclr_model = torch.load('./best.pth')\n",
    "lr = 1e-5\n",
    "optimizer = torch.optim.Adam(simclr_model.parameters(), lr=lr)\n",
    "simclr_model.to(device)\n",
    "loss_list = []\n",
    "for epoch in range(1, EPOCH + 1):\n",
    "    total_loss = 0\n",
    "    x1 = torch.stack([transform(train_data[idx]) for idx in range(NUM_IMAGES)])\n",
    "    x2 = torch.stack([transform(train_data[idx]) for idx in range(NUM_IMAGES)])\n",
    "    train_loader_1 = data.DataLoader(x1, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    train_loader_2 = data.DataLoader(x2, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    for batch_idx, (data_1,data_2) in enumerate(zip(train_loader_1,train_loader_2)):\n",
    "        data_1,data_2 = data_1.to(device), data_2.to(device)\n",
    "        #print( data_1.shape )\n",
    "        optimizer.zero_grad()\n",
    "        u = simclr_model(data_1)\n",
    "        v = simclr_model(data_2)\n",
    "        loss = xt_xent(u, v)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 查看 loss 情況 ###\n",
    "        total_loss +=loss.item()\n",
    "    print(f'Epoch {epoch}: ' +\n",
    "            f'  Loss: {total_loss/29:.6f}')\n",
    "    #### Validation 狀況 ###\n",
    "    val_model = deepcopy(simclr_model)\n",
    "    eval_model = LinearEvaluation(val_model).to(device)\n",
    "    eval_model.to(device)\n",
    "    for batch_idx, (val_data, label) in enumerate(test_loader):\n",
    "        val_data,label = val_data.to(device), label.to(device)\n",
    "        emd_data = eval_model(val_data)\n",
    "        if batch_idx == 0:\n",
    "            embed = emd_data\n",
    "            labels = label\n",
    "        else:\n",
    "            embed = torch.cat((embed,emd_data),0)\n",
    "            labels = torch.cat((labels,label),0)\n",
    "            #print('EBD SHAPE',embed.shape)\n",
    "            #print('Label',labels.shape)\n",
    "    acc = KNN(embed, labels, batch_size=BATCH_SIZE)\n",
    "    print(\"Val Accuracy: %.5f\" % acc)\n",
    "    if acc >= max_acc:\n",
    "        max_acc = acc\n",
    "        torch.save(simclr_model,'./best.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a5bb0",
   "metadata": {},
   "source": [
    "# Testing good model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28efd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBD SHAPE torch.Size([500, 512])\n",
      "Val Accuracy: 0.98400\n"
     ]
    }
   ],
   "source": [
    "###TESTING GOOD MODEL###\n",
    "t = torch.load('./best.pth')\n",
    "t.to(device)\n",
    "a = deepcopy(t)\n",
    "b = LinearEvaluation(a).to(device)\n",
    "#b.load_state_dict(torch.load('./model_checkpoint/simclr_model_new.pt'))\n",
    "b.to(device)\n",
    "test_loader = data.DataLoader(test_img_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "for batch_idx, (val_data, label) in enumerate(test_loader):\n",
    "    val_data,label = val_data.to(device), label.to(device)\n",
    "    emd_data = b(val_data)\n",
    "    if batch_idx == 0:\n",
    "        embed = emd_data\n",
    "        labels = label\n",
    "    else:\n",
    "        embed = torch.cat((embed,emd_data),0)\n",
    "        labels = torch.cat((labels,label),0)\n",
    "        print('EBD SHAPE',embed.shape)\n",
    "                #print('Label',labels.shape)\n",
    "acc = KNN(embed, labels, batch_size=BATCH_SIZE)\n",
    "print(\"Val Accuracy: %.5f\" % acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c5ef1",
   "metadata": {},
   "source": [
    "## Saving numpy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b29fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBD SHAPE torch.Size([7294, 512])\n",
      "float32\n",
      "(7294, 512)\n"
     ]
    }
   ],
   "source": [
    "##SAVE NUMPY file##\n",
    "train_ebd = torch.stack([transform_test(train_data[idx]) for idx in range(NUM_IMAGES)])\n",
    "train_ebd_loader = data.DataLoader(train_ebd, batch_size=BATCH_SIZE, shuffle=False)\n",
    "for batch_idx, data_ebd in enumerate(train_ebd_loader):\n",
    "    data_ebd = data_ebd.to(device)\n",
    "    train_ebd_data =  b(data_ebd)\n",
    "    if batch_idx == 0:\n",
    "        t_embed = train_ebd_data.cpu()\n",
    "    else:\n",
    "        t_embed = torch.cat((t_embed.cpu(),train_ebd_data.cpu()),0)\n",
    "print('EBD SHAPE',t_embed.shape)\n",
    "np.save('310581040.npy',t_embed)\n",
    "embedding = np.load('310581040.npy')\n",
    "print(embedding.dtype)\n",
    "print(embedding.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch_cuda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8be34c3f14941094ba9c02dc298d6639feb690656e0fa02a8f38f062bf322064"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
